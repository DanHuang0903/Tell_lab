import p11 from '../img/project1/p11.png';
import p12 from '../img/project1/p12.png';
import p13 from '../img/project1/p13.jpeg';
import p14 from '../img/project1/p14.png';
import p15 from '../img/project1/p15.png';

import p21 from '../img/project2/p21.jpeg';
import p22 from '../img/project2/p22.jpeg';
import p23 from '../img/project2/p23.jpeg';

import p31 from '../img/project3/p31.jpeg';
import p32 from '../img/project3/p32.jpeg';
import p33 from '../img/project3/p33.jpeg';

import p41 from '../img/project4/p41.jpeg';
import p42 from '../img/project4/p42.jpeg';
import p43 from '../img/project4/p43.jpeg';
import p44 from '../img/project4/p44.jpeg';

import p51 from '../img/project5/p51.jpeg';
import p52 from '../img/project5/p52.jpeg';
import p53 from '../img/project5/p53.jpeg';
import p54 from '../img/project5/p54.jpeg';
import p55 from '../img/project5/p55.jpeg';

export const projectInfo = [
    {
        'name' : 'Virtual Reality Online Orientation (VRO2)',
        'tab':'VR02',
        'subtitle' : 'A VR learning environment aiming to offer the online orientation and training.',
        'project' : 'VR02',
        'imgs' : [p11, p12, p13, p14, p15],
        'description' : [{title:'About This Project', detail:'Virtual Reality Online Orientation (VRO2), a recent VR learning environment developed by the Mizzou TELL research group, aiming to offer the online orientation for newly-admitted students to get acquainted with the school and the program, and study how VR may facilitate learning and training. \n\nIn this VRO2, students will utilize a viewer to take part in five guided activities. All the activities take place in two virtual buildings that resemble the real building where the School of Information Science and Learning Technologies (SISLT) located: Townsend Hall and London Hall.\n\nOverall, students will be able to explore the virtual SISLT buildings, interact with current SISLT faculty and students, and familiar with the documents regarding available resources to new students.'}],
        'link' :''
    },
    {
        'name' : 'Virtual Reality Clinic Room',
        'tab':'VRClinic',
        'subtitle': 'A 3D virtual interactive environment to help 1st-year nursing students take the patient encounter training.',
        'project' : 'VR-Clinic',
        'imgs' : [p21, p22, p23],
        'description' : [{title :'About This Project', detail:'In this project, we designed and developed a 3D virtual interactive environment to help 1st-year nursing students take the patient encounter training, which is part of the Introduction to Nursing course curriculum in a nursing school.\n\nIn order to understand (1) how well nursing students can perform the patient encounter in the 3D virtual interactive environment, and (2) how to use 3D virtual interactive technology to improve nursing students’ performance in a real, physical patient encounter test, we proposed questions:\n\nHow does a 3D virtual interactive experience affect 1st-year nursing students’ conversation skills performance for their first in-person patient encounter training?\nHow do responses from the virtual patient affect students’ question construction, hence, influencing their conversation skills performance?\nThis project is a collaboration between the TELL lab and the Russell D. & Mary B. Shelden Clinical Simulation Center.'}],
        'link' : ''
    },
    {
        'name': 'Immersive VRLab Training (iVRLab)',
        'tab':'iVR',
        'subtitle': 'In this study, we apply the latest VR technology and design a state-of-the-art engineering lab training session – the immersive virtual reality lab (iVRLab).',
        'project' : 'iVRLab',
        'imgs' : [p31, p32, p33],
        'description' : [{title:'About This Project', detail: 'In this study, we apply the latest VR technology and design a state-of-the-art engineering lab training session – the immersive virtual reality lab (iVRLab). The major hardware used for development in this study includes a Dell Alienware desktop computer, an Oculus Rift headset with handheld sensors, and a large display monitor. For software, Unity3D, Maya, and VRTK SDK are used intensively. The training offers a totally immersive, embodied, and interactive experience for the college students to practice the lab work of photolithography, which is an essential technology in fabricating integrated circuit. Learning theories and instructional principles behind the scenes are constructivism, embodied cognition, scaffolding and rewarding systems, multimedia cognitive load theories, and others. The study is to find answers to research questions such as (but not limited to):\n\nWill the iVRLab with embodied features bring positive learning effects in a college engineering lab training? Will it be a feasible complement to the current engineering lab training curriculum?\n\nHow do college students perceive their embodied experience and cognitive load when participating the iVRLab training?\nHow to incorporate design elements into iVRLab to better accommodate learners’ needs and learning characters in an immersive VR context?\n\niVRLab is proudly funded by the University of Missouri Research Council grant, and is a joint project between SISLT TELL lab and the College of Engineering.'}],
        'link' : 'https://www.youtube.com/watch?v=-wQY3Q47wX0'
    },
    {
        'name' : 'Virtual Reality Graduation Celebration amidst the Pandemic',
        'tab':'VR Graduation',
        'subtitle':'We created a 3D Virtual Environment for celebrating the College of Education class of 2020 on May, 15.',
        'project' : 'VR-Graduation',
        'imgs' : [p41, p42, p43, p44],
        'description' : [{title:'About This Project', detail:'We created a 3D Virtual Environment for celebrating the College of Education class of 2020 on May, 15.\n\nThe ultimate goal of doing research is to solve problems and offer solutions to real-world matters. This project brings a timely solution of a 3D virtual-reality-enabled graduation celebration (VRGC) that provides an alternative approach to celebrating university graduation amidst the COVID-19 pandemic. The VRGC is carefully designed with fun, engaging, and interactive activities to compensate for the cancelation of the conventional commencement due to the pandemic. Class of Spring 2020 students may attend this 3D virtual celebration from their home, mingle with their peers, and meet their professors — an unforgettable experience!'}],
        'link' : 'https://fb.watch/4fGHYSQZdH/'

    },
    {
        'name' : 'CAVE Virtual Reality',
        'tab':'CAVE',
        'subtitle' : 'This immersive virtual reality (VR) system with a synchronized motion tracking system will enable foundational and applied research studies across multiple disciplines to gain a better understanding of decision making under complex situations involving human-machine interactions and learning in three-dimensional virtual reality datasets.',
        'project': 'CAVE',
        'imgs' : [p51, p52, p53, p54, p55],
        'description': [{title: 'About This Project', detail:'TELL lab is part of the National Science Foundation (NSF) grant — MRI: Acquisition of a Virtual Reality System for Expert Decision Making and Immersive Learning (NSF # 2018850). This immersive virtual reality (VR) system with a synchronized motion tracking system will enable foundational and applied research studies across multiple disciplines to gain a better understanding of decision making under complex situations involving human-machine interactions and learning in three-dimensional virtual reality datasets. The research activities envisioned will span a broad set of areas such as: computer graphics, computer vision, machine learning, transportation systems, built environment prototyping, public safety during disaster response, computational biology and bioinformatics. The project outcomes will create new knowledge pertaining to immersive application development, training, and personalized learning to benefit end-user groups such as police, fire fighters, civil engineers, public works personnel, transportation engineers, and educators.\n\nWe are working with collaborators from the School of Engineering and the College of Agriculture, Food & Natural Resources to build up CAVE VR-based course modules for collaborative learning on the topic of atmospheric science.\n\nMore information to come.'}],
        'link' : ''
    },
    {
        'name' : 'VR Media Gallery: A case study of sense of presence and engagement in an online digital media course',
        'tab':'VR Media',
        'subtitle':'This study is intended to create an asycronich virtual reality media gallery where students of an online digital media course can present their media creations in an environment created following interactive design guidelines (Kaur, 1997; Parés & Parés, 2001).',
        'project' : 'VR-Media',
        'imgs' : [],
        'description' : [
            {
                title:'Introduction',
                detail:'Virtual Reality has been used to enrich gaming experiences with later inclusion in learning practices. However, its applications to online collaborative education experiences has been reduced due to its limitations in synchronicity (North-Samardzich, Braccini, Spagnoletti, & Za, 2014).\n\nThis study is intended to create an asycronich virtual reality media gallery where students of an online digital media course can present their media creations in an environment created following interactive design guidelines (Kaur, 1997; Parés & Parés, 2001). Their peers can collaborate by reviewing their creations synchronically or asynchronously to their convenience. Thus, enhancing their experience regardless of existing constraints for synchronous interaction. Presence (Witmer & Singer, 1998) will be measured to determine the effectiveness of the Virtual Reality Environment (VRE), and engagement (Webster & Ho, 1997; O’Brien & Toms, 2008) will be measured and contrasted with traditional online methodologies.\n\nThis study is also aiming to exploit known learning benefits from using 3D virtual learning environments (Fowler, 2015) while training students (mostly teachers) in the use of an open source virtual reality environment so they can implement similar experiences in their teaching practices.\n\n'
            },
            {
                title:'Objectives of the Research',
                detail:'The goals of the study are:\n\nTo introduce students to the use an open source virtual reality environment (VRE) as a teaching-learning strategy.\nTo train students in the basic use of a VRE (navigation, views, avatar personalization, objects (prims) creation, setting up script for basic interactions, etc).\nTo encourage students to use VREs as a tools to develop and deliver educational experiences.\n\nThe study is also intended to answer the following research questions:&#13;&#10;Will a VRE for media presentations generate a significant sense of presence in students of a digital media online course?\n\nWill a VRE for media presentations significantly increase students’ engagement in students of a digital media online course (with VR media gallery) compared to results obtained in a traditional delivery of the course (without VR media gallery)?\n\n'
            },
            {
                title:'Discussion of Materials and Methods',
                detail:'Data Collection and Analysis\n\nThe study will have an experimental design. Data will be collected using Qualtrics online surveys. The Online Student Engagement Scale (OSE) (Dixson, 2015) survey will be administered to students taking the online course Introduction to Digital Media during Fall 2018. This is going to be the control group. The same survey will be administered to students taking same course during Spring 2018. The later course will additionally include an introduction to Virtual Reality technology where students are encouraged to present their media creations to their peers in a virtual gallery. This is going to be the experimental group. Feedback from their peers will be collected on a Canvas discussion accessed to each media presentation in the gallery.\n\nThe ICT-SOPI (ICT-Sense of Presence Inventory) questionnaire from Lessiter, Freeman, Keogh, & Davidoff (2000) will be used to collect data on Sense of Presence from students.\n\nTeaching Materials\n\nThe study will be conducted using OpenSimulator, an open source Virtual Reality Environment (VRE) and a virtual world created to simulate the real buildings and spaces of the University of Missouri, including those related to the School of Information Science and Learning Technologies (SISLT). Technical procedures on software utilization will be presented as video tutorials.\n\nThe course chosen to conduct the study is IS_LT 4361/IS_LT 7361 Introduction to Digital Media taught by Assistant Professor Dr. Xinhao Xu during the Spring Semester of 2018. This course usually has an enrollment of 30-40 students. The study will have a duration of two weeks.\n\nTopics included will be:\n\nOpenSimulator viewer (Firestorm) installation and connection to server.\nVisualization modes.\nAvatar personalization.\nNavigation and avatar movement.\nCommunication and interaction with other avatars.\nPrims building, edition, and interaction.\nScripts for media presentations.\n\n'
            },
            {
                title: 'Proposed use of the Funds',
                detail:'The funds will be used to acquire computational equipment for 3D models construction, and VR environment administration, support, and testing:\n\nCYBERPOWERPC Gamer Xtreme GXIVR8020A5 Desktop Gaming PC (Intel i5-8400 6 Core Processor, AMD RX 580 4GB, 8GB DDR4 RAM, 1TB 7200RPM HDD, WiFi, Win 10 Home 64-bit), Black – VR Ready.\n\n'
            },
            {
                title: 'References',
                detail:'Dixson, M. D. (2015). Measuring Student Engagement in the Online Course: The Online Student Engagement Scale (OSE). Online Learning, 19(4).\n\nFowler, C. (2015). Virtual reality and learning: Where is the pedagogy? British Journal of Educational Technology, 46(2), 412–422.\n\nKaur, K. (1997). Designing Virtual Environments for Usability. In S. Howard, J. Hammond, & G. Lindgaard (Eds.), Human-Computer Interaction INTERACT ’97 (pp. 636–639). Boston, MA: Springer US.\n\nLessiter, J., Freeman, J., Keogh, E., & Davidoff, J. (2000). Development of a New Cross-Media Presence Questionnaire: The ITC-Sense of Presence Inventory. Teleoperators and Virtual Environments – Presence.\n\nNorth-Samardzich, A., Braccini, A. M., Spagnoletti, P., & Za, S. (2014). Applying Media Synchronicity Theory to Distance Learning in Virtual Worlds: a Design Science Approach. International Journal of Innovation and Learning, 15.\n\nO’Brien, H. L., & Toms, E. G. (2008). What is user engagement? A conceptual framework for defining user engagement with technology. Journal of the American Society for Information Science and Technology, 59(6), 938–955.\n\nParés, N., & Parés, R. (2001). Interaction-Driven Virtual Reality Application Design (A Particular Case: El Ball del Fanalet or Lightpools). Presence: Teleoperators and Virtual Environments, 10(2), 236–245.\n\nWebster, J., & Ho, H. (1997). Audience Engagement in Multimedia Presentations. SIGMIS Database, 28(2), 63–77.\n\nWitmer, B. G., & Singer, M. J. (1998). Measuring Presence in Virtual Environments: A Presence Questionnaire. Presence: Teleoperators and Virtual Environments, 7(3), 225–240.'
            }
        ]
    }
]